{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangle OpenStreetMaps Data\n",
    "## by Rica Enriquez, July 1, 2015\n",
    "<p>In this project, the OpenStreetMap data for Cambridge, United Kingdom is explored. Having lived there for a few years, I found it an intersting city. It has a good blend of history and modernity. The data was downloaded from https://mapzen.com/data/metro-extracts on July 1, 2015. It was prepared for MongoDB using \"nanoproject_2.py\" and the resulting JSON file was added into a local \"udacity\" database as the \"cambridge\" collection.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Section 0. References\n",
    "<ul>\n",
    "<li>Udacity sample document\n",
    "<ul><li>https://docs.google.com/document/d/1F0Vs14oNEs2idFJR3C_OPxwS6L0HPliOii-QpbmrMo4/pub</li></ul>\n",
    "<li>MongoDB group values by multiple fields</li>\n",
    "<ul><li>http://stackoverflow.com/questions/22932364/mongodb-group-values-by-multiple-fields</li></ul></li></ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1. Problems Encountered in the Map\n",
    "##Removing Underutilized Labels\n",
    "<p>When importing the data, all labels were included at first. Many of these labels were only available for a small fraction of the documents. So, underutilized upper labels and lower lables were removed. If a subset of the dataset is used in the future, removal of labels may  need to be done more judiciously. The \"created\" and \"position\" labels, along with their sublabels, are kept for the purposes of this exercise.</p>\n",
    "<p>Only upper labels were used in at least 1000 documents were kept. This was found previously via MongoDB queries. Similarly, only lower labels that had at least 500 documents were kept. The cleaning of the data is done before the JSON file is created. The code for cleaning can be found in \"nanoproject_2_prep.py.\"</p>\n",
    "<p>The final structure of the collection is seen in the following dictionary, where the sublabels are defined as \"None\" or an array:</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{\"address\": [\"street\",\n",
    "             \"postcode\",\n",
    "             \"housenumber\",\n",
    "             \"housename\",\n",
    "             \"city\",\n",
    "             \"country\",\n",
    "             \"interpolation\"],\n",
    " \"amenity\": None,\n",
    " \"barrier\": None,\n",
    " \"entrance\": None,\n",
    " \"foot\": None,\n",
    " \"highway\": None,\n",
    " \"landuse\": None,\n",
    " \"natural\": None,\n",
    " \"operator\": None,\n",
    " \"source\": [\"name\"],\n",
    " \"created\": [\"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"],\n",
    " \"position\": [\"lat\", \"lon\"]}```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Capitalize Street Names\n",
    "<p> There were a few problems with the street names. \"chieftain\" and \"sweetpea\" were not capitalized. This was fixed using the mapping scheme similar to the \"Improving Street Names\" script from Lesson 6.11.</p>\n",
    "\n",
    "##Remove Documents with Invalid Postcodes\n",
    "<p>All postcodes in Cambridge start with CB. Listing the postcodes in the collection, documents with a postcode of \"SG8 5TF\" is discovered and should not be included since it is for a place in Royston and the Stevenage postcode area. Since there are only two documents in the collection with this postcode, it is an error and not an approach to extend the collection the surrounding area. Additionally the postcode \"CB1\" is incomplete - there should be a second set of three characters. Documents with this postcode are not included.</p>\n",
    "\n",
    "##Update Cities to Cambridge\n",
    "<p>Some cities were \"cambridge\" and not \"Cambridge\", overspecified to \"Girton\" or \"South Cambridgeshire\", or listed as \"11\". However, other information shows that each entry is in Cambridge. Therefore, the \"city\" is updated to \"Cambridge\". This was fixed using a mapping scheme and the function \"update_entry\" in \"nanoproject_2_prep.py.\"</p>\n",
    "\n",
    "##Pare Down Barrier, Entrance, Highway, Landuse, and Operator\n",
    "<p>Some entries for these sublabels were the same, but in a different format. They were updated to be more consistent. These errors were also fixed using a mapping scheme and the function \"update_entry\" in \"nanoproject_2_prep.py.\"</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Section 2. Overview of the Data\n",
    "<p> A statistical overview of the dataset with the MongDB queries used to obtain such statistics are below.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pprint\n",
    "import os\n",
    "\n",
    "# Connect to database\n",
    "client = MongoClient()\n",
    "db = client[\"udacity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of 'cambridge_england.osm' is 61.828774 MB.\n",
      "The size of 'cambridge_england.osm.json' is 70.833688 MB.\n",
      "There are 300419 documents in the set.\n",
      "There are 453 unique users.\n",
      "There are 252027 nodes.\n",
      "There are 48392 ways.\n"
     ]
    }
   ],
   "source": [
    "print \"The size of 'cambridge_england.osm' is\", os.stat(\"cambridge_england.osm\").st_size / 1e6, \"MB.\"\n",
    "print \"The size of 'cambridge_england.osm.json' is\", os.stat(\"cambridge_england.osm.json\").st_size / 1e6, \"MB.\"\n",
    "N = db.cambridge.find().count()\n",
    "print \"There are\", N, \"documents in the set.\"\n",
    "pipeline = [{\"$group\": {\"_id\": \"$created.user\", \"count\": {\"$sum\": 1}}}]\n",
    "print \"There are\", len(list(db.cambridge.aggregate(pipeline))), \"unique users.\"\n",
    "print \"There are\", db.cambridge.find({\"type\": \"node\"}).count(), \"nodes.\"\n",
    "print \"There are\", db.cambridge.find({\"type\": \"way\"}).count(), \"ways.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smb1001 contributed the most to this collection with 79851 documents.\n",
      "120 users contributed once.\n",
      "university bicycle_parking are the top two amenities.\n"
     ]
    }
   ],
   "source": [
    "pipeline = [{\"$group\": {\"_id\": \"$created.user\", \"count\": {\"$sum\": 1}}},\n",
    "            {\"$sort\": {\"count\": -1}},\n",
    "            {\"$limit\": 1}]\n",
    "print list(db.cambridge.aggregate(pipeline))[0]['_id'], \"contributed the most to this collection with\", \\\n",
    "    list(db.cambridge.aggregate(pipeline))[0]['count'], \"documents.\"\n",
    "pipeline = [{\"$group\": {\"_id\": \"$created.user\", \"count\": {\"$sum\": 1}}},\n",
    "            {\"$group\": {\"_id\": \"$count\", \"num_users\": {\"$sum\": 1}}},\n",
    "            {\"$sort\": {\"_id\": 1}},\n",
    "            {\"$limit\": 1}]\n",
    "print list(db.cambridge.aggregate(pipeline))[0]['num_users'], \"users contributed once.\"\n",
    "pipeline = [{\"$group\": {\"_id\": \"$amenity\", \"count\": {\"$sum\": 1}}},\n",
    "            {\"$match\": {\"_id\": {\"$ne\": None}}},\n",
    "            {\"$sort\": {\"count\": -1}},\n",
    "            {\"$limit\": 5}]\n",
    "print list(db.cambridge.aggregate(pipeline))[0][\"_id\"], list(db.cambridge.aggregate(pipeline))[1][\n",
    "    \"_id\"], \"are the top two amenities.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Section 3. Additional Ideas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The Cambridge, England OpenStreetMap dataset is full of information. However, it can be cumbersome to analyze. During the cleaning up stages, many labels and sublables were removed. It may be useful to move the information to an exisiting label rather than having it removed. For example, the information in \"have_riverbank\" and \"trees\" can be moved as sublabels of the \"natural\" label. By moving labels rather than not including them, prematurely removing useful information can be prevented.</p>\n",
    "<p>Since all the labels are known, structuring the labels is possible, though tedious. One way to reduce the labels without excessive information removal is to lower the limit of documents in which the labels need to appear (e.g., from 1000 to 10). However, one must be careful in properly creating the new tree structure. Samples of the label information from the dataset would be useful in making appropriae sublabels and upper labels. After the labeling structure is created, it can be submitted as a proposal for future OpenStreetMap users to follow, prior to submission of new information.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Additonal Data Exploration Using MongoDB Queries\n",
    "<p>Some addresses have house names. It would be interesting to know if there's a certain postal code with the most and if there is an operator that is popular. Additionally, it would be interesting where the top amenities are located.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'_id': u'CB4 1HG', u'count': 17},\n",
      " {u'_id': u'CB3 0EY', u'count': 11},\n",
      " {u'_id': u'CB1 2LJ', u'count': 9},\n",
      " {u'_id': u'CB4 1HH', u'count': 8},\n",
      " {u'_id': u'CB1 2LG', u'count': 7}]\n",
      "[{u'_id': u'University of Cambridge', u'count': 52},\n",
      " {u'_id': u'Clare College (University of Cambridge)', u'count': 6},\n",
      " {u'_id': u'Anglia Ruskin University', u'count': 4},\n",
      " {u'_id': u'Selwyn College (University of Cambridge)', u'count': 4},\n",
      " {u'_id': u'Riverside ECHG', u'count': 3}]\n",
      "[{u'_id': u'restaurant',\n",
      "  u'breakdown': [{u'count': 8, u'postcode': u'CB2 1DP'},\n",
      "                 {u'count': 6, u'postcode': u'CB1 2AS'},\n",
      "                 {u'count': 5, u'postcode': u'CB2 1AB'}],\n",
      "  u'count': 19},\n",
      " {u'_id': u'fast_food',\n",
      "  u'breakdown': [{u'count': 4, u'postcode': u'CB1 7AW'},\n",
      "                 {u'count': 4, u'postcode': u'CB4 1JY'},\n",
      "                 {u'count': 4, u'postcode': u'CB1 2AD'},\n",
      "                 {u'count': 3, u'postcode': u'CB1 7AA'}],\n",
      "  u'count': 15},\n",
      " {u'_id': u'cafe',\n",
      "  u'breakdown': [{u'count': 5, u'postcode': u'CB1 3NF'},\n",
      "                 {u'count': 3, u'postcode': u'CB2 1LA'}],\n",
      "  u'count': 8}]\n"
     ]
    }
   ],
   "source": [
    "# Find the top postcodes with housenames\n",
    "pipeline = [{\"$match\": {\"address.housename\": {\"$exists\": True}}},\n",
    "            {\"$match\": {\"address.postcode\": {\"$ne\": None}}},\n",
    "            {\"$group\": {\"_id\": \"$address.postcode\", \"count\": {\"$sum\": 1}}},\n",
    "            {\"$sort\": {\"count\": -1}},\n",
    "            {\"$limit\": 5}]\n",
    "pprint.pprint(list(db.cambridge.aggregate(pipeline)))\n",
    "\n",
    "# Find the top operators with housenames\n",
    "pipeline = [{\"$match\": {\"address.housename\": {\"$exists\": True}}},\n",
    "            {\"$match\": {\"operator\": {\"$ne\": None}}},\n",
    "            {\"$group\": {\"_id\": \"$operator\", \"count\": {\"$sum\": 1}}},\n",
    "            {\"$sort\": {\"count\": -1}},\n",
    "            {\"$limit\": 5}]\n",
    "pprint.pprint(list(db.cambridge.aggregate(pipeline)))\n",
    "\n",
    "# Find the top amenties with postcodes and sort by postcode\n",
    "pipeline = [{\"$match\": {\"amenity\": {\"$ne\": None}}},\n",
    "            {\"$match\": {\"amenity\": {\"$ne\": \"university\"}}},\n",
    "            {\"$match\": {\"address.postcode\": {\"$ne\": None}}},\n",
    "            {\"$group\": {\"_id\": {\"amenity\": \"$amenity\",\n",
    "                                \"postcode\": \"$address.postcode\"},\n",
    "                        \"count\": {\"$sum\": 1}}},\n",
    "            {\"$sort\": {\"count\": -1}},\n",
    "            {\"$limit\": 10},       \n",
    "            {\"$group\": {\"_id\": \"$_id.amenity\",\n",
    "                        \"breakdown\": {\"$push\": {\n",
    "                            \"postcode\": \"$_id.postcode\", \n",
    "                            \"count\": \"$count\"},},\n",
    "                        \"count\": { \"$sum\": \"$count\"}}},\n",
    "            {\"$sort\": {\"count\": -1}},\n",
    "            {\"$limit\": 3}]\n",
    "pprint.pprint(list(db.cambridge.aggregate(pipeline)))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
